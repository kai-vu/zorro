{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjGOklXrMfx9"
      },
      "source": [
        "# PDF and Prompt extracted tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjwiAfewMfx_",
        "outputId": "2e460642-118f-491c-8703-db995bceeb3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N7aa5537f44b24bfe9d8a78a5d168d750 (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import csv, rdflib, re\n",
        "\n",
        "g = rdflib.Graph()\n",
        "base = rdflib.Namespace('http://Ameneh.org/aircraft.owl#')\n",
        "g.bind(None, base)\n",
        "troubleshooting = csv.DictReader(open('troubleshooting.csv'))\n",
        "for line in troubleshooting:\n",
        "  trouble, cause, remedy=[\n",
        "      base[(re.sub('[^a-zA-z]', '', line [key].title()))]\n",
        "      for key in ['TROUBLE', 'PROBLEM CAUSE', 'REMEDY']\n",
        "  ]\n",
        "\n",
        "    triples = [\n",
        "        (trouble, rdflib.RDFS['subClassOf'], base['Problem']),\n",
        "        (cause, rdflib.RDFS['subClassOf'], base['Problem']),\n",
        "        (trouble, base['hasCause'], cause),\n",
        "        (remedy, rdflib.RDFS['subClassOf'], base['Solution']),\n",
        "        (remedy, base[\"solves\"], cause),\n",
        "    ]\n",
        "    for t in triples:\n",
        "        g.add(t)\n",
        "\n",
        "g.serialize('generated-rdf/troubleshooting.ttl', format='ttl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr-KOJc9MfyC",
        "outputId": "bb55f00f-1d1f-4c0b-be36-76badc38ce09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N158fda171aa34d949667eab45c8d268f (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import csv, rdflib, re\n",
        "\n",
        "g = rdflib.Graph()\n",
        "base = rdflib.Namespace('http://Ameneh.org/aircraft.owl#')\n",
        "g.bind(None, base)\n",
        "\n",
        "def ensure_superclass_chain(part, cls):\n",
        "    if cls not in part_class_lookup:\n",
        "        g.add((cls, rdflib.RDFS['subClassOf'], base['Part']))\n",
        "    else:\n",
        "        parent_cls = part_class_lookup[cls]\n",
        "        g.add((cls, rdflib.RDFS['subClassOf'], parent_cls))\n",
        "        ensure_superclass_chain(cls, parent_cls)\n",
        "\n",
        "part_class_lookup = {}\n",
        "lines = csv.DictReader(open('part-classes.tsv'), delimiter='\\t')\n",
        "for line in lines:\n",
        "    part, cls = [\n",
        "        base[re.sub('[^a-zA-Z]', '', line[key].split('(')[0].title())]\n",
        "        for key in ['Part', 'subClassOf']\n",
        "    ]\n",
        "\n",
        "    triples = [\n",
        "        (part, rdflib.RDFS['label'], rdflib.Literal(line['Part'].title())),\n",
        "        (part, rdflib.RDFS['subClassOf'], cls),\n",
        "        (cls, rdflib.RDFS['label'], rdflib.Literal(line['subClassOf'].title())),\n",
        "    ]\n",
        "    for t in triples:\n",
        "        g.add(t)\n",
        "    part_class_lookup[part] = cls\n",
        "\n",
        "    ensure_superclass_chain(part, cls)\n",
        "\n",
        "parts_catalog = csv.DictReader(open('parts-catalog.csv'))\n",
        "for line in parts_catalog:\n",
        "\n",
        "    system, assembly = [\n",
        "        base[re.sub('[^a-zA-Z]', '', line[key].title())]\n",
        "        for key in ['Section', 'Figure']\n",
        "    ]\n",
        "\n",
        "    cls = base[re.sub('[^a-zA-Z]', '', line['Type'].title())]\n",
        "\n",
        "    label = line['Specifics'].strip() + ' ' + re.sub('[^a-zA-Z]', '', line['Type'].title())\n",
        "\n",
        "    s = base['partnr-' + line['Part Number']]\n",
        "\n",
        "    if cls in part_class_lookup:\n",
        "        part_type_class = cls\n",
        "    else:\n",
        "        part_type_class = base['Part']\n",
        "\n",
        "    triples = [\n",
        "        (s, rdflib.RDFS['subClassOf'], cls),\n",
        "        (s, base['partOf'], assembly),\n",
        "        (s, base['partOf'], system),\n",
        "        (s, base['partNumber'], rdflib.Literal(line['Part Number'])),\n",
        "        (s, rdflib.RDFS['label'], rdflib.Literal(label)),\n",
        "\n",
        "        (assembly, rdflib.RDFS['subClassOf'], base['Assembly']),\n",
        "        (assembly, rdflib.RDFS['label'], rdflib.Literal(line['Figure'])),\n",
        "\n",
        "        (system, rdflib.RDFS['subClassOf'], base['System']),\n",
        "        (system, rdflib.RDFS['label'], rdflib.Literal(line['Section'])),\n",
        "    ]\n",
        "    for t in triples:\n",
        "        g.add(t)\n",
        "\n",
        "    # If the type (cls) is not in the lookup, define it as a subclass of \"Part\"\n",
        "    if cls not in part_class_lookup:\n",
        "        g.add((cls, rdflib.RDFS['subClassOf'], base['Part']))\n",
        "        g.add((cls, rdflib.RDFS['label'], rdflib.Literal(re.sub('[^a-zA-Z]', '', line['Type'].title()))))\n",
        "    else:\n",
        "\n",
        "        ensure_superclass_chain(cls, part_class_lookup[cls])\n",
        "\n",
        "g.serialize('generated-rdf/part-catalog.ttl', format='ttl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgX5iklZ-Cks"
      },
      "outputs": [],
      "source": [
        "import csv, rdflib, re\n",
        "\n",
        "g = rdflib.Graph()\n",
        "base = rdflib.Namespace('http://Ameneh.org/aircraft.owl#')\n",
        "g.bind(None, base)\n",
        "lines = csv.DictReader(\n",
        "    open('prompt-extracted/problem-component-function.tsv'),\n",
        "    delimiter='\\t'\n",
        ")\n",
        "for line in lines:\n",
        "    problem, component, function = [\n",
        "        base[ re.sub('[^a-zA-Z]', '', line[key].split('(')[0].title()) ]\n",
        "        for key in ['defines','functionOf','Function']\n",
        "    ]\n",
        "\n",
        "    triples = [\n",
        "        (function, rdflib.RDFS['subClassOf'], base['Function']),\n",
        "        (function, rdflib.RDFS['label'], rdflib.Literal(line['Function'])),\n",
        "        (function, base['defines'], problem),\n",
        "\n",
        "        (problem, rdflib.RDFS['label'], rdflib.Literal(line['defines'])),\n",
        "\n",
        "        (component, rdflib.RDFS['subClassOf'], base['Component']),\n",
        "        (component, rdflib.RDFS['label'], rdflib.Literal(line['functionOf'])),\n",
        "        (component, base['hasFunction'], function),\n",
        "    ]\n",
        "    for t in triples:\n",
        "        g.add(t)\n",
        "\n",
        "\n",
        "lines = csv.DictReader(\n",
        "    open('prompt-extracted/functions.tsv'),\n",
        "    delimiter='\\t'\n",
        ")\n",
        "for line in lines:\n",
        "    component, function = [\n",
        "        base[ re.sub('[^a-zA-Z]', '', line[key].split('(')[0].title()) ]\n",
        "        for key in ['Component','hasFunction']\n",
        "    ]\n",
        "\n",
        "    triples = [\n",
        "        (function, rdflib.RDFS['label'], rdflib.Literal(line['hasFunction'])),\n",
        "        (function, rdflib.RDFS['subClassOf'], base['Function']),\n",
        "        (component, base['hasFunction'], function),\n",
        "        (component, rdflib.RDFS['subClassOf'], base['Component']),\n",
        "    ]\n",
        "     for t in triples:\n",
        "        g.add(t)\n",
        "\n",
        "\n",
        "lines = csv.DictReader(\n",
        "    open('prompt-extracted/subfunction.tsv'),\n",
        "    delimiter='\\t'\n",
        ")\n",
        "for line in lines:\n",
        "    function, subfunction = [\n",
        "        base[ re.sub('[^a-zA-Z]', '', line[key].split('(')[0].title()) ]\n",
        "        for key in ['subFunctionOf','Function']\n",
        "    ]\n",
        "\n",
        "    triples = [\n",
        "        (subfunction, base['subFunctionOf'], function),\n",
        "    ]\n",
        "    for t in triples:\n",
        "        g.add(t)\n",
        "\n",
        "lines = csv.DictReader(\n",
        "    open('prompt-extracted/dependsOn.tsv'),\n",
        "    delimiter='\\t'\n",
        ")\n",
        "for line in lines:\n",
        "    c1, c2 = [\n",
        "        base[ re.sub('[^a-zA-Z]', '', line[key].split('(')[0].title()) ]\n",
        "        for key in ['Component','dependsOn']\n",
        "    ]\n",
        "\n",
        "    triples = [\n",
        "        (c1, base['dependsOn'], c2),\n",
        "    ]\n",
        "    for t in triples:\n",
        "        g.add(t)\n",
        "\n",
        "\n",
        "g.serialize('generated-rdf/functions.ttl', format='ttl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcvIMjb7MfyD"
      },
      "source": [
        "# Maintenance logbook extraction tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GVDhrH_h-gNA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "log-extracted/problem_extractions_regex.csv: 6169it [00:03, 1571.91it/s]\n",
            "log-extracted/action_extractions_regex.csv: 6169it [00:02, 3064.67it/s]\n",
            "log-extracted/problem_extractions_chatgpt_4o.csv: 6102it [00:05, 1158.18it/s]\n",
            "log-extracted/action_extractions_chatgpt_4o.csv: 6065it [00:05, 1201.81it/s]\n"
          ]
        }
      ],
      "source": [
        "import csv, json, rdflib, re, tqdm\n",
        "a = rdflib.RDF['type']\n",
        "subclassof = rdflib.RDFS['subClassOf']\n",
        "label = rdflib.RDFS['label']\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemma(v):\n",
        "  return lemmatizer.lemmatize(v.lower(), pos='v').upper()\n",
        "\n",
        "event_logs = csv.DictReader(\n",
        "    open('Aircraft_Annotation_DataFile.csv', encoding='utf-8-sig'),\n",
        ")\n",
        "event_logs = { e['IDENT']:e for e in event_logs }\n",
        "\n",
        "def make_event(g, line, event):\n",
        "  log = event_logs[line['id']]\n",
        "  situation = base[event.lower() + str(log['IDENT'])]\n",
        "  g.add( (situation, label, rdflib.Literal(event.lower() + str(log['IDENT']))) )\n",
        "  g.add( (situation, rdflib.DC['description'], rdflib.Literal(log[event.upper()])) )\n",
        "\n",
        "  # id,part,situation,engine,cyl\n",
        "  if line[event]:\n",
        "    event_label = line[event].title() + ' ' + event.title()\n",
        "    event_type = base[event_label.replace(' ','')]\n",
        "    g.add((situation, a, event_type ))\n",
        "    g.add((event_type, subclassof, base[event.title()] ))\n",
        "    g.add((event_type, label, rdflib.Literal(event_label) ))\n",
        "\n",
        "  cyls = re.findall('\\d', line['cylinders']) if line['cylinders'] else [None]\n",
        "  for c in cyls:\n",
        "    if line['part']:\n",
        "      part_name = re.sub('(S$|[^\\s\\w])', '', line['part']).lower()\n",
        "      part = rdflib.BNode()\n",
        "      g.add((situation, base['involves'], part ))\n",
        "\n",
        "      parttype = base[''.join(part_name.title().split())]\n",
        "      g.add((part, a, parttype))\n",
        "      g.add((parttype, label, rdflib.Literal(part_name) ))\n",
        "      partclass = base[part_name.split()[-1].title()]\n",
        "      g.add((parttype, subclassof, partclass))\n",
        "      g.add((partclass, subclassof, base['Part']))\n",
        "\n",
        "      if line['engine']:\n",
        "        g.add((part, base['atEngine'], rdflib.Literal(line['engine']) ))\n",
        "      if c:\n",
        "        g.add((part, base['atCylinder'], rdflib.Literal(int(c)) ))\n",
        "  return situation\n",
        "\n",
        "for source in ['regex', 'chatgpt_4o']:\n",
        "\n",
        "  g = rdflib.Graph()\n",
        "  base = rdflib.Namespace('http://Ameneh.org/aircraft.owl#')\n",
        "  g.bind(None, base)\n",
        "\n",
        "  fname = f'log-extracted/problem_extractions_{source}.csv'\n",
        "  for line in tqdm.tqdm(csv.DictReader(open(fname)), desc=fname):\n",
        "    make_event(g, line, 'problem')\n",
        "\n",
        "  fname = f'log-extracted/action_extractions_{source}.csv'\n",
        "  for line in tqdm.tqdm(csv.DictReader(open(fname)), desc=fname):\n",
        "    problem = base['problem' + str(line['id'])]\n",
        "    action = make_event(g, line, 'action')\n",
        "    g.add( (action, base['dealsWith'], problem) )\n",
        "\n",
        "\n",
        "  g.serialize(f'generated-rdf/extractions_{source}.ttl', format='ttl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thvnu-fx-rlq"
      },
      "outputs": [],
      "source": [
        "g = rdflib.Graph()\n",
        "base = rdflib.Namespace('http://Ameneh.org/aircraft.owl#')\n",
        "g.bind(None, base)\n",
        "\n",
        "for row in open('part-links.tsv'):\n",
        "  part_name, part_scores = row.split('\\t')\n",
        "  part_uri = base[re.sub('(S$|\\W)', '', part_name.title())]\n",
        "  for candidate, score in json.loads(part_scores).items():\n",
        "    link = rdflib.BNode()\n",
        "    g.add((part_uri, base['isMaybe'], link))\n",
        "    g.add((link, base['linkCandidate'], base[candidate]))\n",
        "    g.add((link, base['linkScore'], rdflib.Literal(score)))\n",
        "\n",
        "g.serialize(f'generated-rdf/part-links.ttl', format='ttl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rdf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
