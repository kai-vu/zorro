{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Linking\n",
    "## Problem\n",
    "We have 3 data sources that describe the underlying system in aircraft maintenance. The data sources are:\n",
    "1. Maitenance logs\n",
    "2. Parts catalog\n",
    "3. troubleshooting guide\n",
    "\n",
    "These data sources are for the most part separate. The Maintenance logs are completely unstructured and only consist of text parts. The parts catalog is a structured data source that contains information about the parts used in the aircraft. Many of the parts mentioned in the maintenance logs could be found in the parts catalog. Finding links between the parts in the maintenance logs and the parts catalog would be useful for further analysis.\n",
    "\n",
    "## 1. Data Extraction\n",
    "see gpt.ipynb\n",
    "We use the problem extractions from gpt 4 to extract the parts from the maintenance logs. \n",
    "\n",
    "## 2. Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load in problem extractions and parts catalog\n",
    "problem_extractions = pd.read_csv('problem_extractions_chatgpt_4o.csv')\n",
    "action_extractions = pd.read_csv('action_extractions_chatgpt_4o.csv')\n",
    "parts_catalog = pd.read_csv('pdf-extracted/parts-catalog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SHAFT ASSEMBLY', 'VALVE', 'SPARK PLUG', 'FITTING', 'TUBE', 'HOSE', 'IMPELLER', 'INSERT', 'ROD ASSEMBLY', 'SHROUD TUBE ASSEMBLY', 'OIL FILTER BASE ASSEMBLY', 'BODY ASSEMBLY', 'CONNECTOR', 'MAGNETO', 'KEY', 'TUBE ASSEMBLY', 'BUSHING', 'SPACER', 'SCREEN ASSEMBLY', 'CLIP', 'CYLINDER ASSEMBLY', 'SCREEN', 'PLUNGER ASSEMBLY', 'OIL FILTER', 'PLUG', 'COVER', 'CRANKSHAFT ASSEMBLY', 'PIN', 'CONNECTING ROD ASSEMBLY', 'FUEL PUMP', 'BAFFLE ASSEMBLY', 'SOCKET', 'SHIM', 'HOUSING ASSEMBLY', 'SEAT', 'GUIDE', 'CRANKCASE ASSEMBLY (Roller tappet engines)', 'PLATE', 'SPRING', 'ZIP STRAP', 'GAGE ASSEMBLY', 'GEAR ASSEMBLY', 'CRANKCASE ASSEMBLY KIT (Roller tappet engines)', 'THRUST BUTTON', 'CONNECTION', 'HOUSING', 'RETAINER', 'SHAFT', 'GEAR', 'IMPELLER KIT', 'CAMSHAFT ASSEMBLY', 'ADAPTER ASSEMBLY', 'VALVE ASSEMBLY', 'LINK', 'RING', 'BRACKET', 'NIPPLE', 'GASKET', 'STARTER ASSEMBLY', 'CARBURETOR', 'CAP', 'CRANKCASE ASSEMBLY', 'ELBOW', 'PIPE', 'CRANKCASE ASSEMBLY KIT', 'CLAMP', 'COTTER PIN', 'HARNESS ASSEMBLY', 'SEAL', 'STRUT', 'LOCKPLATE', 'BODY', 'IMPELLER ASSEMBLY', 'FLANGE', 'PISTON', 'NUT', 'SCREW', 'BALL', 'BEARING', 'ADAPTER', 'CAMSHAFT ASSEMBLY (Roller tappet engines)', 'SUPPORT ASSEMBLY', 'WASHER', 'DOWEL', 'STRAP', 'PLUNGER', 'STUD', 'BOLT', 'ROCKER ASSEMBLY', 'OIL SEAL', 'SUMP ASSEMBLY'}\n",
      "Exact matches: 2.59%\n",
      "Split matches: 42.25%\n"
     ]
    }
   ],
   "source": [
    "# create a set with all the unique parts in the parts catalog\n",
    "part_set = set()\n",
    "for index, row in parts_catalog.iterrows():\n",
    "    part_set.add(str(row['Type']))\n",
    "    \n",
    "print(part_set)\n",
    "\n",
    "# calculate the % of parts exactly mentioned in the problem extractions (==) \n",
    "# that are in the parts catalog\n",
    "count = 0\n",
    "for index, row in problem_extractions.iterrows():\n",
    "    if row['part'] in part_set:\n",
    "        count += 1\n",
    "\n",
    "\n",
    "print(f\"Exact matches: {count*100/len(problem_extractions):.2f}%\")\n",
    "# from analyzing the process, it seems that most parts\n",
    "# mentioned in the problem extractions that aren't in the parts catalog\n",
    "# seem to be collections, like 'ENGINE' or 'INTAKE',\n",
    "# abbreviations, like 'CYL'\n",
    "# or still have location identifiers attached to them, like in 'ROCKER COVER GASKETS'\n",
    "\n",
    "\n",
    "# idea: split up the parts in problem extractions by spaces\n",
    "count = 0\n",
    "for index, row in problem_extractions.iterrows():\n",
    "    parts = str(row['part']).split(' ')\n",
    "    for part in parts:\n",
    "        if part in part_set:\n",
    "            count += 1\n",
    "            break\n",
    "        \n",
    "print(f\"Split matches: {count*100/len(problem_extractions):.2f}%\")\n",
    "# much higher percentage of parts mentioned in the problem extractions\n",
    "# however there is a lot of noise as well\n",
    "# like part: INTAKE TUBE GASKET match: TUBE\n",
    "# this is where a more structured approach could be useful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lexing & Parsing\n",
    "Using the problem extractions, we want to identify a few things:\n",
    "- The main part (like \"GASKET\" in \"ROCKER COVER GASKET\")\n",
    "- which words are useful for linking\n",
    "\n",
    "I've chosen to use a parser to extract the main part and useful words. In hindsight it is probably overkill with the current uses. The parser could be replaced with something simpler, however the current setup works just fine.\n",
    "\n",
    "### 3.1 Lexer\n",
    "The lexer is responsible for tokenizing the input text. It splits the text into words and categorizes them into different types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('INTAKE', 'PART'), ('TUBE', 'PART'), ('GASKET', 'PART')]\n",
      "[('BLACK', 'ATTRIBUTE'), ('BOX', 'ATTRIBUTE'), ('SEAL', 'PART')]\n"
     ]
    }
   ],
   "source": [
    "# TOKENS: PART, ATTRIBUTE, CONTEXT\n",
    "# all words are classified as either a part, an attribute, or context\n",
    "# CONTEXT is a word that doesn't fit as either a PART or ATTRIBUTE\n",
    "\n",
    "# The token classification is done by a simple lookup in a wordmap\n",
    "# which is populated with all the parts in the parts catalog\n",
    "# and other words that are known to be parts or attributes\n",
    "\n",
    "TOKENS = ['PART', 'ATTRIBUTE', 'CONTEXT']\n",
    "ATTRIBUTES = [\n",
    "    \"BLACK\",\n",
    "    \"BOX\",\n",
    "    \"ANGLE\",\n",
    "    \"INTERCONNECT\",\n",
    "    \"MOUNTING\",\n",
    "    \"BLAST\",\n",
    "    \"INNER\",\n",
    "    \"SNAP\",\n",
    "    \"PUSH\",\n",
    "    \"BOTTOM\",\n",
    "    \"WIRE\",\n",
    "    \"BACK\",\n",
    "    \"INDUCTION\"\n",
    "]\n",
    "wordmap = {\n",
    "    #\"ENGINE\": 'PART', # ENGINE would match with all parts, practically useless\n",
    "    \"INTAKE\": 'PART', # a subset of parts, but we treat it as a part, even though we can't find it in the parts catalog\n",
    "}\n",
    "\n",
    "# make each part in the parts catalog a PART\n",
    "for part in part_set:\n",
    "    wordmap[part] = 'PART'\n",
    "    wordmap[part + \"S\"] = 'PART'\n",
    "    \n",
    "    # if the part is an assembly, remove the last word\n",
    "    splt = part.split(' ')\n",
    "    if len(splt) > 1 and splt[-1] == 'ASSEMBLY':\n",
    "        wordmap[' '.join(splt[:-1])] = 'PART'\n",
    "\n",
    "# add all attributes as Tokens\n",
    "for attribute in ATTRIBUTES:\n",
    "    if attribute in wordmap:\n",
    "        print(\"WARNING: attribute already in wordmap\")\n",
    "    wordmap[attribute] = 'ATTRIBUTE'\n",
    "\n",
    "def lex(sentence):\n",
    "    \"\"\"\n",
    "    Tokenize a sentence into PART, ATTRIBUTE, and CONTEXT tokens\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    words = str(sentence).split(' ')\n",
    "    for word in words:\n",
    "        if word in wordmap:\n",
    "            tokens.append((word, wordmap[word]))\n",
    "        else:\n",
    "            tokens.append((word, 'CONTEXT'))\n",
    "    return tokens\n",
    "\n",
    "print(lex(\"INTAKE TUBE GASKET\"))\n",
    "print(lex(\"BLACK BOX SEAL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Parser\n",
    "The parser creates a tree structure from the token stream. The tree structure is used to extract the main part and useful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main (ctx (), part (PART INTAKE (), part (PART TUBE (), part (PART GASKET (),  (), ), ), ), ctx (), )\n",
      "main (ctx (), part (ATTRIBUTE BLACK (), part (ATTRIBUTE BOX (), part (PART SEAL (),  (), ), ), ), ctx (), )\n"
     ]
    }
   ],
   "source": [
    "# tree structure:\n",
    "# main: ctx part ctx\n",
    "# part: ATTRIBUTE part\n",
    "#     | PART part\n",
    "#     | -\n",
    "# ctx : CONTEXT ctx\n",
    "#     | -\n",
    "# we don't care about ambiguity in the parsing,\n",
    "# as examples are small enough to brute force the parsing\n",
    "\n",
    "class ParseNode:\n",
    "    def __init__(self, type, value, children):\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.children = children\n",
    "        \n",
    "    def __str__(self):\n",
    "        s = self.type\n",
    "        if self.value != '':\n",
    "            s += ' ' + self.value\n",
    "        s += ' ('\n",
    "        for child in self.children:\n",
    "            s += str(child) + ', '\n",
    "        s += ')'\n",
    "        return s\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "    \n",
    "class UnparsableException(Exception):\n",
    "    pass\n",
    "\n",
    "def parse(tokens):\n",
    "    \"\"\"\n",
    "    Parse a list of tokens into a tree structure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ctx1 = parse_ctx(tokens)\n",
    "        part = parse_part(tokens, True)\n",
    "        ctx2 = parse_ctx(tokens)\n",
    "        if tokens != []:\n",
    "            raise UnparsableException\n",
    "        return ParseNode('main', '', [ctx1, part, ctx2])\n",
    "    except UnparsableException:\n",
    "        return None\n",
    "\n",
    "def parse_part(tokens, force=False):\n",
    "    if tokens == []:\n",
    "        if force:\n",
    "            raise UnparsableException\n",
    "        return ParseNode(\"\", \"\", [])\n",
    "    \n",
    "    next = tokens.pop(0)\n",
    "    if next[1] == 'CONTEXT':\n",
    "        tokens.insert(0, next)\n",
    "        if force:\n",
    "            raise UnparsableException\n",
    "        return ParseNode(\"part\", \"\", [])\n",
    "    if next[1] == 'ATTRIBUTE':\n",
    "        leaf = ParseNode('ATTRIBUTE', next[0], [])\n",
    "        return ParseNode('part', \"\", [leaf, parse_part(tokens, force)])\n",
    "    elif next[1] == 'PART':\n",
    "        leaf = ParseNode('PART', next[0], [])\n",
    "        return ParseNode('part', \"\", [leaf, parse_part(tokens, False)])\n",
    "    else:\n",
    "        raise UnparsableException\n",
    "\n",
    "def parse_ctx(tokens):\n",
    "    if tokens == []:\n",
    "        return ParseNode(\"ctx\", \"\", [])\n",
    "    \n",
    "    next = tokens.pop(0)\n",
    "    if next[1] == 'CONTEXT':\n",
    "        leaf = ParseNode('CONTEXT', next[0], [])\n",
    "        return ParseNode('ctx', \"\", [leaf, parse_ctx(tokens)])\n",
    "    else:\n",
    "        tokens.insert(0, next)\n",
    "        return ParseNode(\"ctx\", \"\", [])\n",
    "    \n",
    "print(parse(lex(\"INTAKE TUBE GASKET\")))\n",
    "print(parse(lex(\"BLACK BOX SEAL\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Main Part Extraction\n",
    "The main part is usually the last part of the part name. For example, in \"ROCKER COVER GASKET\", \"GASKET\" is the main part. The parser extracts the main part by looking at the deepest PART node in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PART GASKET ()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_main_part(node):\n",
    "    \"\"\"\n",
    "    Find the main PART node in the tree structure\n",
    "    \"\"\"\n",
    "    # Usually this is the last part in the sentence,\n",
    "    # which corresponds to the deepest part in the tree\n",
    "    \n",
    "    # we use a depth first search to find the deepest part\n",
    "    if node.type == 'main':\n",
    "        return find_main_part(node.children[1])\n",
    "    elif node.type == 'part':\n",
    "        for child in node.children[::-1]: # iterate in reverse order\n",
    "            if child.type == 'part':\n",
    "                d = find_main_part(child)\n",
    "                if d is not None:\n",
    "                    return d\n",
    "            elif child.type == 'PART':\n",
    "                return child\n",
    "    return None\n",
    "\n",
    "find_main_part(parse(lex(\"INTAKE TUBE GASKET\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Useful Words Extraction\n",
    "The useful words are almost all the words in the part name. However, parts may be pluralized. In these cases the parser removes the pluralization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['INTAKE', 'TUBE', 'GASKETS', 'GASKET']\n"
     ]
    }
   ],
   "source": [
    "# find all buzzwords\n",
    "# which are basicallly all words in the sentence.\n",
    "# for parts, we also add the singular form\n",
    "def find_buzzwords(node,):\n",
    "    buzzwords = []\n",
    "    if node.type == 'main':\n",
    "        for child in node.children:\n",
    "            buzzwords.extend(find_buzzwords(child))\n",
    "    elif node.type == 'ctx':\n",
    "        for child in node.children:\n",
    "            buzzwords.extend(find_buzzwords(child))\n",
    "    elif node.type == 'part':\n",
    "        for child in node.children:\n",
    "            buzzwords.extend(find_buzzwords(child))\n",
    "    elif node.type == 'ATTRIBUTE':\n",
    "        buzzwords.append(node.value)\n",
    "    elif node.type == 'PART':\n",
    "        buzzwords.append(node.value)\n",
    "        if node.value.endswith('S'):\n",
    "            buzzwords.append(node.value[:-1]) # remove the S\n",
    "    elif node.type == 'CONTEXT':\n",
    "        buzzwords.append(node.value)\n",
    "    \n",
    "    return buzzwords\n",
    "\n",
    "print(find_buzzwords(parse(lex(\"INTAKE TUBE GASKETS\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Part Graph\n",
    "Parts from the parts catalog are loaded into a graph. This graph also records related words for each part, and which parts are related to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "#   STRUCTURING THE PARTS CATALOG\n",
    "#==============================================================================\n",
    "# Idea: create a graph with all parts being nodes, these parts have relations\n",
    "# to other parts, like being a subpart of an assembly, or being a part of the same assembly\n",
    "# with this graph structure, we may be able to identify parts based on mentions of other parts\n",
    "\n",
    "class Part:\n",
    "    def __init__(self, part_number, part_type, specifics):\n",
    "        self.part_number = part_number\n",
    "        self.part_type = part_type\n",
    "        self.specifics = specifics\n",
    "        self.connections = set()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.part_number + ' (' + self.part_type + ')'\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "\n",
    "class Connection:\n",
    "    def __init__(self, part1, part2, relation):\n",
    "        self.part1 = part1\n",
    "        self.part2 = part2\n",
    "        self.relation = relation\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.part1.part_number + ' ' + self.relation + ' ' + self.part2.part_number\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "    \n",
    "class Section:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.assemblies = {}\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name + ' (' + str(len(self.parts)) + ' parts)'\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n",
    "    \n",
    "class Assembly:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parts = {}\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.name + ' (' + str(len(self.parts)) + ' parts)'\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return self.__str__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Part Linking\n",
    "When Populating the Part graph, we record which words were mentioned for each part. From this information, we can create the `word_hints` map. This map maps each word to the parts that contain that word. \n",
    "\n",
    "When linking parts from the maintenance logs, we can use the `word_hints` map to find the parts that contain the words in the part name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17F19357 (ROCKER ASSEMBLY),\n",
       " 74637 (BUSHING),\n",
       " LW-13790 (SHAFT),\n",
       " LW-12892 (THRUST BUTTON),\n",
       " 75906 (GASKET),\n",
       " 61247 (COVER),\n",
       " 66610 (BUSHING)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_hints = {}\n",
    "sections = {}\n",
    "\n",
    "# populate the graph with parts from the parts catalog\n",
    "for index, row in parts_catalog.iterrows():\n",
    "    section = row['Section']\n",
    "    assembly = row['Figure']\n",
    "    \n",
    "    # if the section or assembly doesn't exist yet, create it\n",
    "    if section not in sections:\n",
    "        sections[section] = Section(section)\n",
    "    if assembly not in sections[section].assemblies:\n",
    "        sections[section].assemblies[assembly] = Assembly(assembly)\n",
    "    \n",
    "    part_name = str(row['Part Number'])\n",
    "    \n",
    "    # some parts occur multiple times in the parts catalog\n",
    "    # skip them (for now), if assembly words are added,\n",
    "    # this needs to be changed\n",
    "    if part_name in sections[section].assemblies[assembly].parts:\n",
    "        #print(\"WARNING: part already in assembly:\", part_name)\n",
    "        continue\n",
    "    \n",
    "    part = Part(part_name, row['Type'], row['Specifics'])\n",
    "    sections[section].assemblies[assembly].parts[part.part_number] = part\n",
    "    \n",
    "    # for the related words, take the specifics and type of the part\n",
    "    related_words = []\n",
    "    related_words.extend(str(row['Specifics']).split(' '))\n",
    "    related_words.extend(str(row['Type']).split(' '))\n",
    "    related_words = [str(w).upper() for w in set(related_words)]\n",
    "    for w in related_words:\n",
    "        if w in word_hints:\n",
    "            word_hints[w].append(part)\n",
    "        else:\n",
    "            word_hints[w] = [part]\n",
    "        \n",
    "    part.words = related_words\n",
    "\n",
    "# build relations between parts\n",
    "# for now only Assembly relations are added\n",
    "# but others can easily be added as well\n",
    "for section in sections.values():\n",
    "    for assembly in section.assemblies.values():\n",
    "        for part in assembly.parts.values():\n",
    "            for other in assembly.parts.values():\n",
    "                if part != other:\n",
    "                    c = Connection(part, other, 'ASSEMBLY')\n",
    "                    part.connections.add(c)\n",
    "                    other.connections.add(c)\n",
    "\n",
    "# we can now search for all parts related to a word, such as 'ROCKER'\n",
    "word_hints[\"ROCKER\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each part in the maintenance logs, we have a list of words that are related to the part in question, and we have a map of words to possible parts. \n",
    "\n",
    "This means that for each entry in the maintenance logs, we can find the catalog parts similar to the part in the maintenance logs. However, to find a good match, we need some way to score the similarity between the parts.\n",
    "\n",
    "To do this, we devise a very simple scoring system that scores the similarity between a part in the catalog and the entry. It basically counts how many words overlap between the entry and the catalog part.\n",
    "\n",
    "$$ \\text{score}(c, e) = |\\text{words}(c) \\cap \\text{words}(e)| $$\n",
    "where $c$ is a part in the catalog, $e$ is an entry in the maintenance logs, and $\\text{words}(x)$ is the set of words in $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{17F19357 (ROCKER ASSEMBLY): 1, 74637 (BUSHING): 1, LW-13790 (SHAFT): 1, LW-12892 (THRUST BUTTON): 1, 75906 (GASKET): 3, 61247 (COVER): 2, 66610 (BUSHING): 1, 69106 (COVER): 1, 60430 (COVER): 1, 03D23350 (COVER): 1, 06E19769-0.63 (GASKET): 1, 61173 (GASKET): 1, 69551 (GASKET): 1, 61183 (GASKET): 1, 8313 (GASKET): 1, 06B23862 (GASKET): 1, 76510 (GASKET): 1, 60096 (GASKET): 1, 73818 (GASKET): 1, 62224 (GASKET): 1, 06E19769-1.25 (GASKET): 1, 66224 (GASKET): 1, 71973 (GASKET): 1, 77611 (GASKET): 1, LW-13353 (GASKET): 1, 06E19769-1.00 (GASKET): 1, 72059 (GASKET): 1}\n"
     ]
    }
   ],
   "source": [
    "def make_buzz_ranking(buzzwords):\n",
    "    # rank the parts based on the number of times a word\n",
    "    # overlaps with the words of a part\n",
    "    ranking = {}\n",
    "    for buzzword in buzzwords:\n",
    "        if buzzword in word_hints:\n",
    "            for part in word_hints[buzzword]:\n",
    "                if part in ranking:\n",
    "                    ranking[part] += 1\n",
    "                else:\n",
    "                    ranking[part] = 1\n",
    "    return ranking\n",
    "\n",
    "example = parse(lex(\"ROCKER COVER GASKETS\"))\n",
    "words = find_buzzwords(example)\n",
    "ranking = make_buzz_ranking(words)\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Candidate Selection\n",
    "In addition of the useful words per entry, we also have the main part. We can use the main part to filter the parts in the catalog. We only consider a part a candidate if the main part exactly corresponds to the part type in the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(75906 (GASKET), 3),\n",
       " (06E19769-0.63 (GASKET), 1),\n",
       " (61173 (GASKET), 1),\n",
       " (69551 (GASKET), 1),\n",
       " (61183 (GASKET), 1),\n",
       " (8313 (GASKET), 1),\n",
       " (06B23862 (GASKET), 1),\n",
       " (76510 (GASKET), 1),\n",
       " (60096 (GASKET), 1),\n",
       " (73818 (GASKET), 1),\n",
       " (62224 (GASKET), 1),\n",
       " (06E19769-1.25 (GASKET), 1),\n",
       " (66224 (GASKET), 1),\n",
       " (71973 (GASKET), 1),\n",
       " (77611 (GASKET), 1),\n",
       " (LW-13353 (GASKET), 1),\n",
       " (06E19769-1.00 (GASKET), 1),\n",
       " (72059 (GASKET), 1)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out the parts that don't match the type\n",
    "def get_candidates(ranking, part_type):\n",
    "    candidates = []\n",
    "    for part, score in ranking.items():\n",
    "        if (part.part_type == part_type \n",
    "        or part.part_type == part_type + ' ASSEMBLY'\n",
    "        or part.part_type + 'S' == part_type):\n",
    "            candidates.append((part, score))\n",
    "    return candidates\n",
    "\n",
    "main_part = find_main_part(example).value\n",
    "get_candidates(ranking, main_part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Scoring Refinement\n",
    "Earlier, we scored every part in the catalog. For the candidate scoring we also want to account for parts related to the candidate. \n",
    "\n",
    "$$ \\text{ranking}(c, e) = \\text{score}(c, e) * B + \\sum_{r \\in \\text{assembly}(c)} \\text{score}(r, e) * R $$\n",
    "where $c$ is the candidate, $e$ is the entry, $B$ is the base score factor, and $R$ is the relation score factor. $\\text{assembly}(x)$ is the set of related parts in the same assembly as $x$, excluding parts that are already candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 5 # multiplier for the base score of a candidate\n",
    "R = 1 # multiplier for the score of a related part\n",
    "def rank_candidates(ranking, candidates):\n",
    "    scores = {}\n",
    "    for candidate in candidates:\n",
    "        score = 0\n",
    "        for connection in candidate[0].connections:\n",
    "            subjectpart = connection.part1 if connection.part1 != candidate[0] else connection.part2\n",
    "            \n",
    "            # ignore if the part is of the same type as the candidate\n",
    "            # this is to prevent a specific kind of bias where\n",
    "            # parts of the same type and figure boost each other.\n",
    "            # even though there is nothing from the entry that suggests this\n",
    "            if subjectpart.part_type == candidate[0].part_type:\n",
    "                continue\n",
    "            if subjectpart in ranking:\n",
    "                score += ranking[subjectpart] * R\n",
    "        \n",
    "        # apply base score of the candidate\n",
    "        score += candidate[1] * B\n",
    "        scores[candidate[0]] = score\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function combines the previous functions to get the ranked candidates\n",
    "def get_ranked_candidates(node, secondary=None):\n",
    "    dpart = find_main_part(node).value\n",
    "    bz = find_buzzwords(node)\n",
    "    if dpart is None: # no part found\n",
    "        #print(\"No part found for\", node)\n",
    "        return None\n",
    "    \n",
    "    ranking = make_buzz_ranking(bz)\n",
    "    \n",
    "    candidates = get_candidates(ranking, dpart)\n",
    "    #if len(candidates) == 0:\n",
    "        #print(\"No candidates found for\", dpart)\n",
    "    return rank_candidates(ranking, candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsable: 72.89%\n",
      "Unparsable extractions: ['ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'OIL DIPSTICK', 'BRAKE', 'COWL MOUNTS', 'OIL PRESS', 'OIL PRESS', nan, nan, 'FUEL PRESS', 'ENGINE', nan, 'ENGINE', 'ENGINE', 'BRAKE LININGS', 'ENGINE', 'ENGINE', nan, nan, nan, nan, nan, nan, nan, nan, 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'LACING CORD', 'INTAKES', 'ENGINE', 'ENGINE', 'RIVET', 'INTAKES', nan, 'INSPECTION PANEL', 'INTAKES', 'INTAKES', 'INTAKES', 'INTAKES', 'INTAKES', 'INTAKES', 'INTAKES', 'FUEL INJ LINES STANDOFF', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'INNER CYL BAFFLE TIE ROD', 'INTAKES', 'INTAKES', 'BACK TOP BAFFLE', 'ENGINE IDLE', 'INTAKES', 'AFT BAFFLE ATTACH PLATE', 'OIL COOLER BAFFLING', nan, 'OIL RETURN LINE', 'COWL SHOCK MOUNTS', nan, nan, nan, nan, 'INTAKES', 'OIL RETURN LINE', 'INTAKES', 'THROTTLE LINKAGE DOG BONE', 'INTAKES', 'ENG BAFFLING', 'FIREWALL', 'ENG BAFFLING', 'INDUCTION', 'DIPSTICK', 'INTAKES', 'INTAKES', 'INTAKES', 'HARDWARE', 'HARDWARE', 'STAND OFF', nan, 'INTAKES', nan, 'OIL COOLER', 'EGT WIRE PROBE STANDOFFS', 'OIL COOLER LINE', 'INTAKES', 'PRIMER LINE SLEEVE', nan, nan, nan, nan, 'IGNITION LEAD LACING CORE', nan, nan, 'INTAKES', 'OIL COOLER STAND OFFS', 'INTAKES', 'INTAKES', 'ENGINE', nan, nan, 'MIXTURE CONTROL', nan, 'INTAKE I/B BOLT HOLE', 'CORNER PATCH', nan, 'CYL', nan, 'OIL', 'IDLE MIXTURE', 'IDLE MIXTURE', 'IDLE MIXTURE', 'BAFFLE SPARK PLUG ACCESS BUTTON', nan, 'INTAKES', 'INTAKES', 'RIVET', 'OIL RETURN LINES', 'OIL RETURN LINES', 'OIL RETURN', 'WIRING HOLDER', 'COWL SHOCK MOUNT', 'ENGINE', 'RIVET', 'RIVETS', 'STAND OFF', nan, 'INTAKES', 'MIXTURE', 'INDUCTION AIR FILTER', 'LOWER DEFLECTORS', 'ENGINE', 'ENGINE', 'ENGINE', nan, nan, 'RIVNUT', 'ENGINE N1 RPM', 'TABS', nan, nan, nan, nan, nan, 'INTAKES', 'INTAKE CYL GASKET', nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, 'AIR DOOR', 'FIRST STAGE COMPRESSOR ROTOR', 'ENGINE', 'BAFFLE BUTTON PLUG', 'CASE HALVES', 'PARTICLE SEPERATOR', 'ENGINE', 'INTAKES', 'INTAKES', nan, 'INTAKES', 'MUFFLER HEAT MUFF', nan, 'OIL COOLER', nan, 'INTAKES', nan, nan, 'BAFFLING', 'COOLING BAFFLE CONNECTING ROD', 'INTAKES', 'INTAKES', 'COOLING BAFFLING RIVETS', 'INTAKES', 'ENGINE', nan, 'RIVET', 'RIVET', nan, nan, nan, nan, nan, nan, nan, nan, 'ENGINE COWL DZUS FASTENERS', nan, nan, nan, nan, 'THROTTLE LINKAGE', 'INTAKES', 'TOOL', 'BAFFLE (AFT) SEAL', nan, nan, nan, nan, nan, nan, 'COWL SHOCK MOUNT', nan, 'TAC GEN', 'TAC GEN', 'TAC GEN', 'INTAKES', 'INTAKES', 'ANCHOR STANDBY ASSY', 'BAFFLE TIE ROD', nan, 'INTAKES', 'BAFFLE TIE ROD', 'INTAKES', 'INTAKES', 'BLEED AIR DUCT', nan, nan, nan, nan, 'BAFFLE TIE ROD', 'AFT BAFFLE CORNER SUPPORT BRACKET', nan, nan, 'INTAKES', nan, 'ENGINE PAN DRAIN LINE CLUSTER', 'CYL', 'CYL', 'CYL', nan, 'ENGINE', 'FUEL PLACARD', 'ENGINE', 'BAFFLE REINFORCEMENT ANGLE', 'MUFFLER', 'ENGINE', 'ENGINE', 'ENGINE', 'OIL COOLER LINE', 'EGT', 'EGT', 'INTAKES', 'INTAKES', 'ENGINE', 'INTAKES', 'RIVET', 'HARDWARE', 'BAFFLE O/B SPRING', 'BAFFLE I/B SPRING', nan, nan, nan, 'ROCKERS', 'INTAKES', 'INTAKES', 'ENG BAFFLING', nan, 'ENGINE', 'EXCITER LEAD', 'INTAKES', nan, nan, nan, 'INTAKES', nan, nan, 'AFT BAFFLING', nan, 'TEMP PROBE', 'INTAKES', nan, 'INTAKES', 'INTAKES', 'INTAKES', 'BAFFLING', 'INTAKES', 'INTAKES', 'BAFFLE TIE ROD', 'OIL COOLER', 'ROCKER ARM COVER', 'INTAKES', nan, nan, nan, nan, nan, 'RIVET', 'UPPER BAFFLE HOLE PLUGS', nan, nan, 'BAFFLE BUTTON PLUG', 'INTERCYLINDER BAFFLE CONNECTING ROD', 'UPPER COWLING', 'UPPER ENG BAFFLING', 'SPIRAL WRAP', '#3 CYL BAFFLING', '#2 CYL BAFFLING', 'ENGINE', nan, nan, 'ENGINE RPM', 'CYL', 'ENGINE', 'OIL RETURN LINES', 'INTAKES', 'INTAKES', 'INTAKES', nan, 'INTAKES', 'ENGINE', 'ENGINE', 'ENG PLUGS SAFETY WIRE', 'INTAKES', 'INTAKES', nan, 'OUTER BAFFLING', 'HOISTING LOOP', 'HOISTING LOOP', 'INTAKES', 'INTAKES', 'BAFFLE TIE ROD', 'OUTER CYL BAFFLING', 'PROP/ENGINE', 'INTAKES', 'ENGINE BAFFLE ATTACH BRACKET', 'BAFFLE TIE ROD', 'BACK BONE', 'BACK BONE', 'QUICK DRAIN', 'QUICK DRAIN', 'INTAKES', 'TYWRAP', 'SIMULATED OIL LEAK', 'WIRING', 'CHT', 'EGT', 'CHT', 'ENGINE', 'INTAKES', 'INTAKES', 'INTAKES', 'BAFFLE TIE ROD', nan, 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'INTAKES', nan, 'DUCT TAPE', 'WRENCH', 'ENGINE', 'ENGINE', 'ENGINE', nan, 'IGNTION LEAD STAND OFF', 'START ASSIST', nan, 'INTAKES', 'CYL', 'CYL', 'CYL', 'CYL', 'ENGINE', 'INTAKES', 'INTAKES', 'CYL', 'CYL', 'THROTTLE', 'BLEED AIR LINE', 'ENGINE', 'ENGINE', 'ENGINE', 'INTAKES', 'DIPSTICK', 'CABLE SHEATH', 'OIL COOLER', 'RIVET', 'FOD', 'FOD', 'BAFFLE TIE WIRE', 'INTAKES', nan, 'FIREWALLS', 'BAFFLE TIE ROD', 'GROMMET', 'NACELLE', 'NACELLE', 'NACELLE', 'START ASSIST', nan, nan, 'START ASSIST', 'INTAKES', 'INTAKES', 'PRIMER LINE', 'INTAKES', 'ENG COWLING', 'ENG COWLING', 'ENGINE', 'BAFFLING', 'YOKES', 'OIL COOLER', 'INTERCYLINDER BAFFLE TENSION WIRE', 'IGN TOP LEADS', nan, nan, 'INTAKES', nan, nan, 'MAG', 'MAG', 'MAG', 'ENGINE', 'ENGINE SCROLL', nan, nan, 'OIL RETURN LINE', nan, 'BAFFLE INNER TIE WIRE', 'OIL COOLER', 'OIL COOLER', 'OIL COOLER', 'OIL COOLER', 'OIL COOLER', 'OIL COOLER', nan, nan, nan, nan, nan, nan, nan, nan, 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', nan, nan, 'INTAKES', nan, nan, nan, nan, nan, 'THROTTLE', 'OIL RETURN LINE INTER-COOLER BAFFLING GROMMET', nan, 'INTAKES', 'BAFFLE TIE ROD THREADS', 'BAFFLING', 'ENGINE', 'INTAKES', 'OIL COOLER', 'FUEL INJECTOR', 'OIL COOLER', nan, 'CYL', 'CYL', 'CYL', nan, 'INTAKES', 'RIVET', 'GROMMET', 'OIL COOLER', nan, nan, 'TIE RODS', nan, 'INTAKES', nan, nan, nan, nan, 'BACKBONE', 'INTAKES', nan, 'ENGINE', nan, nan, 'POP RIVETS', 'INTAKES', 'INTAKES', 'INTAKES', 'OIL COOLER', 'INTAKES', 'ROCKER COVER DRAIN HOSE CLAMPS', 'OIL RETURN LINES', nan, nan, nan, nan, nan, nan, nan, 'BAFFLING', 'BAFFLING', 'PROP', 'INTAKES', 'INTAKES', '1ST STAGE COMP BLADE', nan, 'ENGINE', 'START ASSIST', 'INTAKES', 'ENGINE', 'CASE HALVES', nan, 'MAG', 'UPPER EXHAUST SHROUD', 'INTAKES', nan, 'INTAKES', 'INTAKES', nan, nan, nan, nan, 'INTAKES', 'INTAKES', 'MIXTURE', nan, nan, nan, nan, 'INTAKES', nan, nan, nan, nan, nan, nan, nan, nan, 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'INTAKES', nan, nan, 'BAFFLE TIE WIRE', nan, nan, nan, 'TOP BACK BONE', 'TOP BACK BONE', 'INTAKES', nan, nan, nan, 'LOWER OIL COOLER LINE', nan, 'ENGINE', 'INTAKES', 'ANGLE', nan, nan, nan, nan, 'PROP', 'CYL', 'INTAKES', nan, nan, nan, nan, 'THROTTLE', 'HARDWARE', 'INTAKES', 'GROUNDING WIRE', nan, 'RIVET HEAD', 'INTAKES', 'OIL', 'INTAKES', 'OIL', 'INTAKES', 'PROP', 'PROP', 'INTAKES', 'PROP', 'ENGINE', 'ENGINE', 'ENGINE', 'PROP', 'ENGINE', nan, 'BAFFLING', 'INTAKES', 'PROP', 'OIL COOLER WEATHER STRIPPING', 'BAFFLING', 'BAFFLE TIE ROD', 'ENGINE AIR FILTER', 'INTAKES', 'INTAKES', 'CARB HEAT BOX ARM', 'MAG', 'OIL COOLERS', 'MAG', 'INTAKES', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'INTAKES', nan, 'INTAKES', nan, nan, 'INTAKES', nan, nan, 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'OIL COOLER', nan, 'ENGINE COWL', nan, nan, nan, nan, nan, 'FOD', 'INTAKES', 'INTAKES', 'INTAKES', 'OIL COOLER', nan, nan, nan, nan, nan, nan, 'ENGINE RPM', 'ENGINE RPM', 'ENGINE RPM', nan, nan, nan, nan, 'PROP', 'PROP', nan, nan, nan, nan, nan, 'CYL', 'CYL', nan, 'HARDWARE', 'HARDWARE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', nan, nan, nan, 'ENGINE', 'CARB AIRBOX', 'ENGINE COWL CAM LOCK', 'INTAKES', 'ZIP TIES', 'CHAFE TAPE', 'ENGINE', 'FWD BAFFLING', 'ZIP TIES', 'DUCTING', nan, 'INTAKES', 'INTAKES', 'INTAKES', nan, nan, nan, nan, nan, nan, nan, nan, nan, 'BACK BONE', 'INTAKES', 'BACK BONE', nan, nan, nan, nan, nan, nan, nan, 'LWR ENG COWLS', 'MAG', 'INTAKES', 'PROP', 'CYL', nan, nan, nan, 'INTAKES', nan, nan, nan, 'ENGINE', 'INTAKES', 'INTAKES', 'LOWER ENGINE COWL CAM LOCK', 'ENGINE', 'OIL PRESSURE LINE SUPPORT BRACKET/FUEL FLOW TRANSDUCER WIRE', 'INTAKES', 'BAFFLING', nan, nan, nan, nan, nan, 'RIVETS', nan, nan, 'PUSH ROD EXHAUST TUBE', 'PUSH ROD EXHAUST TUBE', 'OIL PRESSURE', 'OIL PRESSURE', 'ALT', 'PUSH ROD SHROUD TUBE SEALS', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'FRONT CRANKSHAFT OIL PLUG', 'FRONT CRANKSHAFT OIL PLUG', nan, nan, 'ZIP TIES', nan, nan, 'LONG BAFFLE TIE ROD', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', 'ENGINE', nan, nan, nan, nan, nan, nan, nan, 'ROCKERS & PUSH RODS', 'OIL RETURN LINE', 'CRANKSHAFT FRONT SEAL', 'CRANKSHAFT FRONT SEAL', 'ENGINE', nan, nan, 'WRENCH', nan, 'CARB AIR BOX', nan, nan, 'BAFFLING', 'PRIMER LINE', nan, 'BATTERY CASE', 'ENGINE ASSY', nan, nan, 'ENGINE B', 'ENGINE', 'INTAKES', 'BAFFLE TIE ROD BOLT', 'BOLT FOR ALT SUPPORT', 'ENGINE', 'SCREW BEHIND OIL DIPSTICK TUBE', 'INTAKES', 'EXHAUST SIDE PUSH ROD & ROCKER', 'INTAKES', 'EXHAUST PUSH ROD & ROCKER', 'INTAKES', 'EXHAUST PUSH ROD & ROCKER ARM', 'RIVET', nan, nan, nan, 'HARDWARE', 'CHT', 'CYL', 'CYL', 'ENGINE']\n"
     ]
    }
   ],
   "source": [
    "# check parsability of all problem extractions\n",
    "parsable = 0\n",
    "parsed_extractions = []\n",
    "unparsable = []\n",
    "for index, row in problem_extractions.iterrows():\n",
    "    result = parse(lex(row['part']))\n",
    "    # parse returns None if the extraction is unparsable\n",
    "    if result is not None:\n",
    "        parsable += 1\n",
    "        parsed_extractions.append(result)\n",
    "    else:\n",
    "        lexed = lex(row['part'])\n",
    "        unparsable.append(row['part'])\n",
    "        \n",
    "print(f\"Parsable: {parsable*100/len(problem_extractions):.2f}%\")\n",
    "print(f\"Unparsable extractions: {unparsable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linking success rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "succesful extractions: 62.34%\n",
      "succesful identifications: 33.06%\n"
     ]
    }
   ],
   "source": [
    "def inv(d):\n",
    "    \"\"\"\n",
    "    Inverts a dictionary\n",
    "    \"\"\" \n",
    "    r = {}\n",
    "    for k, v in d.items():\n",
    "        if v in r:\n",
    "            r[v].append(k)\n",
    "        else:\n",
    "            r[v] = [k]\n",
    "    return r\n",
    "\n",
    "\n",
    "# run the function on all parsed extractions\n",
    "ranked_candidates = []\n",
    "for parsed in parsed_extractions:\n",
    "    res = get_ranked_candidates(parsed)\n",
    "    ranked_candidates.append(res)\n",
    "\n",
    "extraction_successes = 0\n",
    "identified_parts = []\n",
    "MIN_SCORE = 4\n",
    "for c in ranked_candidates:\n",
    "    if c is not None and len(c) > 0:\n",
    "        extraction_successes += 1\n",
    "        # get the part with the highest score\n",
    "        # and only add it if it is the only part with that score\n",
    "        m = max(c.values())\n",
    "        invc = inv(c)\n",
    "        if len(invc[m]) == 1 and m > MIN_SCORE:\n",
    "            identified_parts.append(invc[m][0])\n",
    "        #else:\n",
    "            #print(\"Ambiguity in ranking:\", invc[m],\"with score\", m)\n",
    "        \n",
    "print(f\"succesful extractions: {extraction_successes * 100 / len(problem_extractions):.2f}%\")\n",
    "print(f\"succesful identifications: {len(identified_parts) * 100 / len(problem_extractions):.2f}%\")\n",
    "\n",
    "# scrolling through the output, it seems that the parser is able to identify\n",
    "# clearly mentioned parts, like seals and gaskets\n",
    "# but struggles a lot with more general mentions, like 'ENGINE' or 'INTAKE'\n",
    "# obviously this makes sense, there is not a single part that is called 'ENGINE' or 'INTAKE'\n",
    "# but rather a collection of parts that make up the engine or intake system\n",
    "\n",
    "# now it is unknown wether it actually identifies the correct part.\n",
    "# it does seem to identify the correct part in most cases, but it is hard to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Possible Extensions\n",
    "#### Scoring\n",
    "The current scoring method is very simple, but has a few biases. It rewards parts with more words, and it rewards parts with more related parts. This could be improved by using a more advanced scoring system. An example could be to define the initial score as: \n",
    "$$ \\text{score}(c, e) = \\frac{|\\text{words}(c) \\cap \\text{words}(e)|}{|\\text{words}(c)|} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_buzz_ranking(buzzwords):\n",
    "    ranking = {}\n",
    "    for buzzword in buzzwords:\n",
    "        if buzzword in word_hints:\n",
    "            for part in word_hints[buzzword]:\n",
    "                if part in ranking:\n",
    "                    ranking[part] += 100.0 / len(set(chain(word_hints[buzzword],buzzwords)))\n",
    "                else:\n",
    "                    ranking[part] = 100.0 / len(set(chain(word_hints[buzzword],buzzwords)))\n",
    "    return ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integration of action extractions\n",
    "Currently we only use the problem extractions to identify parts. Every entry also has an action extraction. This could be used to further refine the linking, especially in cases where the symptoms were very broad, but a specific part was replaced.\n",
    "\n",
    "The action extractions are very similar to the problem extractions, and could be used in the same way, or even together with the problem extractions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate Assembly and Section names into related words\n",
    "Currently only the type and details columns are used to find related words. The assembly and section names could also be used for this. Some words are very clearly mentioned in the Assembly names, such as Intake."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
